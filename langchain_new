import pandas as pd
from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain.chat_models import AzureChatOpenAI
from langsmith import Client
from langchain.vectorstores import Pinecone  # Example: Using Pinecone as VectorDB
from langchain.embeddings import OpenAIEmbeddings
from langchain.schema.runnable import RunnablePassthrough, RunnableSequence

# Initialize LangSmith client
langsmith_client = Client()

# Configure Azure OpenAI for generation and validation
llm = AzureChatOpenAI(
    api_key="your_azure_openai_api_key",  # Replace with your Azure OpenAI API key
    api_version="2023-05-15",  # Use the latest version
    azure_endpoint="https://<your-resource-name>.openai.azure.com/",  # Replace with your Azure endpoint
    deployment_name="gpt-4",  # Replace with your deployed model name
    temperature=0.7
)

# Configure embeddings for VectorDB (e.g., OpenAI embeddings)
embeddings = OpenAIEmbeddings(openai_api_key="your_openai_api_key")

# Initialize VectorDB (e.g., Pinecone)
vector_db = Pinecone(
    index_name="your-pinecone-index",  # Replace with your Pinecone index name
    embedding=embeddings,
    api_key="your_pinecone_api_key"  # Replace with your Pinecone API key
)

# System message with organization instructions
system_message = """
You are a data modeling assistant. Your task is to generate logical names and descriptions for columns in a dataset.
Follow these guidelines:
1. Logical names and descriptions should be descriptive and concise.
2. Use camelCase or snake_case for naming conventions.
3. Avoid using special characters or spaces.
4. Ensure the logical name and description align with the column's original name and description.
"""

# Define prompt for generating logical name and description together
generate_name_and_description_prompt = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(system_message),
    HumanMessagePromptTemplate.from_template("""
    Generate a logical name and description for the following column:
    - Name: {name}
    - Description: {description}

    Respond in the following format:
    Logical Name: <logical_name>
    Logical Description: <logical_description>
    """)
])

# Define prompt for validation
validate_prompt = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(system_message),
    HumanMessagePromptTemplate.from_template("""
    Validate whether the following logical names and descriptions are appropriate for their respective columns:
    {rows}
    """)
])

# Create runnable sequences for generation and validation
generate_name_and_description_sequence = RunnableSequence(
    RunnablePassthrough(),  # Pass through the input
    generate_name_and_description_prompt,  # Use the generate name and description prompt
    llm  # Use the LLM to generate the logical name and description
)

validate_sequence = RunnableSequence(
    RunnablePassthrough(),  # Pass through the input
    validate_prompt,  # Use the validate prompt
    llm  # Use the LLM to validate the logical names and descriptions
)

# Function to retrieve relevant data from VectorDB
def retrieve_from_vectordb(query, top_k=3):
    """
    Retrieve relevant data from VectorDB based on a query.
    """
    results = vector_db.similarity_search(query, k=top_k)
    return [result.page_content for result in results]  # Return the content of the retrieved documents

# Function to parse the generated logical name and description
def parse_name_and_description(response):
    """
    Parse the logical name and description from the LLM response.
    """
    logical_name = response.split("Logical Name: ")[1].split("\n")[0].strip()
    logical_description = response.split("Logical Description: ")[1].strip()
    return logical_name, logical_description

# Function to process the CSV
def process_csv(input_csv_path, output_csv_path, chunk_size=5):
    # Load the CSV file
    df = pd.read_csv(input_csv_path)

    # Generate logical names and descriptions
    df[['logical_name', 'logical_description']] = df.apply(
        lambda row: parse_name_and_description(
            generate_name_and_description_sequence.invoke({
                "name": row['name'],
                "description": row['description']
            })
        ), axis=1, result_type="expand"
    )

    # Validate logical names and descriptions in chunks
    validation_results = []
    for i in range(0, len(df), chunk_size):
        chunk = df.iloc[i:i + chunk_size]
        rows_to_validate = "\n".join(
            f"- Name: {row['name']}, Description: {row['description']}, Logical Name: {row['logical_name']}, Logical Description: {row['logical_description']}"
            for _, row in chunk.iterrows()
        )
        validation_result = validate_sequence.invoke({"rows": rows_to_validate})
        validation_results.extend([validation_result] * len(chunk))

    # Add validation results to the DataFrame
    df['validation_result'] = validation_results

    # Retrieve relevant data from VectorDB for each row
    df['vectordb_results'] = df.apply(
        lambda row: retrieve_from_vectordb(query=row['description']), axis=1
    )

    # Save the results to a new CSV file
    df.to_csv(output_csv_path, index=False)

if __name__ == "__main__":
    # Path to the input CSV file
    input_csv_path = "input
