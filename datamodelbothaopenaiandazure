import os
import pandas as pd
from dotenv import load_dotenv
from langchain.document_loaders import CSVLoader
from langchain.schema import Document
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from difflib import SequenceMatcher
import csv

# Load environment variables
load_dotenv()
open_api_key = os.getenv("AZURE_API_KEY")
os.environ["OPENAI_API_KEY"] = open_api_key

# Initialize embedding model
embedding_adamodel = OpenAIEmbeddings(model="text-embedding-ada-002")

# CSV file containing source of truth metadata
csv_file_path = "source_of_truth_metadata.csv"

# Read the CSV file into a Pandas DataFrame
df = pd.read_csv(csv_file_path)

# Lowercase all column names and values
df.columns = df.columns.str.lower()
for col in ['logical_column_name', 'library', 'maxlength', 'data_type', 'protection', 'lob', 'description']:
    df[col] = df[col].apply(lambda x: x.lower() if isinstance(x, str) else x)

df_source = df

# Create documents from the DataFrame for vector database storage
documents = []
for _, row in df_source.iterrows():
    combined_text = (f"The logical column '{row['logical_column_name']}' belongs to library '{row['library']}' "
                     f"with a maximum length of '{row['maxlength']}', data type '{row['data_type']}', "
                     f"protected under '{row['protection']}' group, and has a Line of business '{row['lob']}' "
                     f"which is described as '{row['description']}'.")

    metadata = {
        "logical_column_name": row["logical_column_name"],
        "library": row["library"],
        "description": row["description"],
        "lob": row["lob"],
        "protection": row["protection"],
        "data_type": row["data_type"],
        "max_length": row["maxlength"]
    }

    doc = Document(page_content=combined_text, metadata=metadata)
    documents.append(doc)

# Create embeddings for the documents
embeddings = [embedding_adamodel.embed_query(doc.page_content) for doc in documents]

# Store metadata in Chroma vector database
vector_store = Chroma(embedding_function=embedding_adamodel, persist_directory="./sorchroma_db")
vector_store.add_texts([doc.page_content for doc in documents], metadatas=[doc.metadata for doc in documents])

print("Source metadata stored in vector database.")
output_file_path = "processed_metadata.csv"
output_df = pd.DataFrame([doc.metadata for doc in documents])  # Extract metadata from documents
output_df.to_csv(output_file_path, index=False)

# Initialize OpenAI API via LangChain
llm = ChatOpenAI(model="gpt-4", temperature=0)

def get_openai_suggestion(input_row, closest_match):
    # Define the prompt template
    prompt_template = """
    We have identified the following closest match for a column:
    Input logical column: '{input_logical_column}'
    Stored logical column: '{stored_logical_column}'
    Input protection group: '{input_protection}', Stored protection group: '{stored_protection}'
    Input data type: '{input_data_type}', Stored data type: '{stored_data_type}'
    
    Based on the stored values, do the input protection group and data type need corrections? 
    If yes, please suggest the correct protection group and data type for the input column.
    """

    # Prepare the prompt with actual values
    prompt = PromptTemplate(
        template=prompt_template,
        input_variables=[
            "input_logical_column", "stored_logical_column",
            "input_protection", "stored_protection",
            "input_data_type", "stored_data_type"
        ]
    ).format(
        input_logical_column=input_row['logical_column_name'],
        stored_logical_column=closest_match.metadata['logical_column_name'],
        input_protection=input_row['protection'],
        stored_protection=closest_match.metadata['protection'],
        input_data_type=input_row['data_type'],
        stored_data_type=closest_match.metadata['data_type']
    )

    # Send the prompt to OpenAI and retrieve the response
    response = llm.invoke(prompt)
    return response['choices'][0]['message']['content']  # Access the content of the response

def similarity_percentage(a, b):
    """Calculate similarity ratio as a percentage."""
    return similarity(a, b) * 100

def similarity(a, b):
    """Calculate similarity ratio between two strings."""
    return SequenceMatcher(None, a, b).ratio()

# CSV file containing input data for validation
input_csv_file = "updated_bank_risk_metadata.csv"
df_input = pd.read_csv(input_csv_file)

# Define function to suggest the correct protection group and datatype based on stored metadata
def validate_and_suggest(df_input, vector_store, top_k=5):
    results = []

    for _, input_row in df_input.iterrows():
        # Find the closest match for logical column name using semantic similarity
        logical_column_input = input_row['logical_column_name']
        query_embedding = embedding_adamodel.embed_query(logical_column_input)
        
        # Search in vector database for similar logical column names
        search_results = vector_store.similarity_search_by_vector(query_embedding, k=top_k)
        
        if search_results:
            # Identify the most similar logical column name
            closest_match = max(search_results, key=lambda res: similarity(logical_column_input, res.metadata['logical_column_name']))
            sim_percentage = similarity_percentage(logical_column_input, closest_match.metadata['logical_column_name'])
            print(f"Similarity percentage for '{logical_column_input}' and '{closest_match.metadata['logical_column_name']}': {sim_percentage:.2f}%")
            
            # Check if the protection group or datatype needs to be corrected
            suggested_pg_group = None
            suggested_data_type = None
            
            if closest_match.metadata['protection'] != input_row['protection']:
                suggested_pg_group = closest_match.metadata['protection']
            
            if closest_match.metadata['data_type'] != input_row['data_type']:
                suggested_data_type = closest_match.metadata['data_type']

            # Call OpenAI to determine if protection group or data type needs correction
            openai_suggestion = get_openai_suggestion(input_row, closest_match)
            
            # Gather all fields and add suggestions if there's a mismatch
            suggestion = {
                "input_table_name": input_row["table_name"],
                "input_logical_column": logical_column_input,
                "input_physical_column": input_row["physical_column_name"],
                "input_data_type": input_row["data_type"],
                "input_protection": input_row["protection"],
                "stored_protection": closest_match.metadata["protection"],
                "stored_data_type": closest_match.metadata["data_type"],
                "suggested_protection": suggested_pg_group if suggested_pg_group else "Correct",
                "suggested_data_type": suggested_data_type if suggested_data_type else "Correct",
                "openai_suggestion": openai_suggestion
            }
            results.append(suggestion)

    return results

# Example usage
validation_results = validate_and_suggest(df_input, vector_store)

# Define output CSV file path
output_csv_file = "validation_results.csv"

# Write validation results to an output CSV file
with open(output_csv_file, mode='w', newline='') as file:
    writer = csv.DictWriter(file, fieldnames=[
        "input_table_name", "input_logical_column", "input_physical_column",
        "input_data_type", "input_size", "input_precision", "input_protection",
        "stored_protection", "stored_data_type", "suggested_protection", "suggested_data_type", "openai_suggestion"
    ])
    writer.writeheader()
    writer.writerows(validation_results)

print(f"Validation results written to {output_csv_file}")
------------------------------------------------------------------------------------------------------------------

import os
from dotenv import load_dotenv
import pandas as pd
from langchain.document_loaders import CSVLoader
from langchain.schema import Document
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma

# Load environment variables
load_dotenv()
open_api_key = os.getenv("API_KEY")
os.environ["OPENAI_API_KEY"] = open_api_key

# Initialize embedding model
embedding_adamodel = OpenAIEmbeddings(model="text-embedding-ada-002")

# CSV file containing source of truth metadata
csv_file_path = "source_of_truth_metadata.csv"

# Read the CSV file into a Pandas DataFrame
df = pd.read_csv(csv_file_path)

# Lowercase all column names
df.columns = df.columns.str.lower()  # Lowercase column names

# Lowercase all values in the DataFrame
#df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)  # Lowercase all string values
df['logical_column_name'] = df['logical_column_name'].apply(lambda x: x.lower() if isinstance(x, str) else x)
df['library'] = df['library'].apply(lambda x: x.lower() if isinstance(x, str) else x)
df['maxlength'] = df['maxlength'].apply(lambda x: x.lower() if isinstance(x, str) else x)
df['data_type'] = df['data_type'].apply(lambda x: x.lower() if isinstance(x, str) else x)
df['protection'] = df['protection'].apply(lambda x: x.lower() if isinstance(x, str) else x)
df['lob'] = df['lob'].apply(lambda x: x.lower() if isinstance(x, str) else x)
df['description'] = df['description'].apply(lambda x: x.lower() if isinstance(x, str) else x)
df_source=df

# Create documents from the DataFrame for vector database storage
documents = []
for _, row in df_source.iterrows():
    combined_text = (f"The logical column '{row['logical_column_name']}' belongs to library '{row['library']}' "
                 f"with a maximum length of '{row['maxlength']}', data type '{row['data_type']}', "
                 f"protected under '{row['protection']}' group, and has a Line of business '{row['lob']}' which is described as '{row['description']}'.")


    metadata = {
        "logical_column_name": row["logical_column_name"],
        "library": row["library"],
        "description": row["description"],
        "lob": row["lob"],
        "protection": row["protection"],
        "data_type": row["data_type"],
        "max_length": row["maxlength"]
    }

    doc = Document(page_content=combined_text, metadata=metadata)
    documents.append(doc)

# Create embeddings for the documents
embeddings = [embedding_adamodel.embed_query(doc.page_content) for doc in documents]

# Store metadata in Chroma vector database
vector_store = Chroma(embedding_function=embedding_adamodel, persist_directory="./sorchroma_db")
vector_store.add_texts([doc.page_content for doc in documents], metadatas=[doc.metadata for doc in documents])

print("Source metadata stored in vector database.")
output_file_path = "processed_metadata.csv"
output_df = pd.DataFrame([doc.metadata for doc in documents])  # Extract metadata from documents
output_df.to_csv(output_file_path, index=False)


from difflib import SequenceMatcher
import csv
import openai
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
import requests

# Initialize OpenAI API via LangChain
llm = ChatOpenAI(model="gpt-4", temperature=0) 

def get_openai_suggestion(input_row, closest_match):
    # Define the prompt template
    prompt_template = """
    We have identified the following closest match for a column:
    Input logical column: '{input_logical_column}'
    Stored logical column: '{stored_logical_column}'
    Input protection group: '{input_protection}', Stored protection group: '{stored_protection}'
    Input data type: '{input_data_type}', Stored data type: '{stored_data_type}'
    
    Based on the stored values, do the input protection group and data type need corrections? 
    If yes, please suggest the correct protection group and data type for the input column.
    """

    # Fill in the prompt with actual values
    prompt = PromptTemplate(
        template=prompt_template,
        input_variables=[
            "input_logical_column", "stored_logical_column",
            "input_protection", "stored_protection",
            "input_data_type", "stored_data_type"
        ]
    ).format(
        input_logical_column=input_row['logical_column_name'],
        stored_logical_column=closest_match.metadata['logical_column_name'],
        input_protection=input_row['protection'],
        stored_protection=closest_match.metadata['protection'],
        input_data_type=input_row['data_type'],
        stored_data_type=closest_match.metadata['data_type']
    )

    # Send the prompt to OpenAI and retrieve the response
    response = llm.invoke(prompt)
    return response.content  # Return the cleaned-up response


def similarity(a, b):
    """Calculate similarity ratio between two strings."""
    return SequenceMatcher(None, a, b).ratio()

# CSV file containing input data for validation
input_csv_file = "updated_bank_risk_metadata.csv"
df_input = pd.read_csv(input_csv_file)

# Define function to suggest the correct PG group and datatype based on stored metadata
def validate_and_suggest(df_input, vector_store, top_k=5):
    results = []

    for _, input_row in df_input.iterrows():
        # Find the closest match for logical column name using semantic similarity
        logical_column_input = input_row['logical_column_name']
        query_embedding = embedding_adamodel.embed_query(logical_column_input)
        
        # Search in vector database for similar logical column names
        search_results = vector_store.similarity_search_by_vector(query_embedding, k=top_k)
        
        if search_results:
            # Identify the most similar logical column name
            closest_match = max(search_results, key=lambda res: similarity(logical_column_input, res.metadata['logical_column_name']))
            
            # Check if the PG group or datatype needs to be corrected
            suggested_pg_group = None
            suggested_data_type = None
            
            if closest_match.metadata['protection'] != input_row['protection']:
                suggested_pg_group = closest_match.metadata['protection']
            
            if closest_match.metadata['data_type'] != input_row['data_type']:
                suggested_data_type = closest_match.metadata['data_type']

                # Call OpenAI to determine if PG group or data type needs correction
            openai_suggestion = get_openai_suggestion(input_row, closest_match)
            
            # Gather all fields and add suggestions if there's a mismatch
            suggestion = {
                "input_table_name": input_row["table_name"],
                "input_logical_column": logical_column_input,
                "input_physical_column": input_row["physical_column_name"],
                "input_data_type": input_row["data_type"],
                "input_PGGroup": input_row["protection"],
                "stored_PGGroup": closest_match.metadata["protection"],
                "stored_data_type": closest_match.metadata["data_type"],
                "suggested_PGGroup": suggested_pg_group if suggested_pg_group else "Correct",
                "suggested_data_type": suggested_data_type if suggested_data_type else "Correct",
                "OpenAI_suggestion": openai_suggestion
            }
            results.append(suggestion)

    return results

# Example usage
validation_results = validate_and_suggest(df_input, vector_store)

# Define output CSV file path
output_csv_file = "validation_results.csv"

# Write validation results to an output CSV file
with open(output_csv_file, mode='w', newline='') as file:
    writer = csv.DictWriter(file, fieldnames=[
        "input_table_name", "input_logical_column", "input_physical_column",
        "input_data_type", "input_size", "input_precision", "input_PGGroup",
        "stored_PGGroup", "stored_data_type", "suggested_PGGroup", "suggested_data_type","OpenAI_suggestion"
    ])
    writer.writeheader()
    writer.writerows(validation_results)

print(f"Validation results written to {output_csv_file}")
              
