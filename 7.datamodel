import pandas as pd

def split_into_batches(df, batch_size):
    # Extract first word of field_name
    df['field_group'] = df['field_name'].str.split().str[0]
    
    # Create a unique group key
    df['group_key'] = df['table_name'] + '_' + df['field_group']
    
    # Sort to maintain order (optional)
    df = df.sort_values(['table_name', 'field_group'])
    
    # Group records based on `group_key`
    grouped = df.groupby('group_key')
    
    # Create batches
    batches = []
    current_batch = []
    current_size = 0

    for _, group in grouped:
        group_size = len(group)
        
        # If adding the current group exceeds batch size, start a new batch
        if current_size + group_size > batch_size and current_batch:
            batches.append(pd.concat(current_batch))
            current_batch = []
            current_size = 0

        # Add group to the current batch
        current_batch.append(group)
        current_size += group_size

    # Add any remaining batch
    if current_batch:
        batches.append(pd.concat(current_batch))
    
    return batches

# Sample Data
data = {
    'table_name': ['A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'],
    'field_name': ['name first', 'name last', 'address street', 'address zip', 'city name', 'city code', 'state full', 'state short']
}

df = pd.DataFrame(data)

# Split into batches
batch_size = 3  # Set batch size
batches = split_into_batches(df, batch_size)

# Print results
for i, batch in enumerate(batches):
    print(f"Batch {i+1}:\n", batch, "\n")
